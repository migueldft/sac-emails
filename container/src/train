#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import json
import os
import pickle
import joblib
import sys
import traceback
import pandas as pd
import numpy as np

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

from CustomClasses import NLTKPreprocessor

# These are the paths to where SageMaker mounts interesting things in your container.
prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

cv_list = [
    'Ainda não devolvi meu produto e quero saber sobre processo de troca / devolução',
    'Estou arrependido, quero cancelar/trocar o produto',
    'Como utilizar o cupom/vale',
    'Qual o prazo para devolução do valor que paguei?',
    'Como recupero meu login e senha de acesso'
]

map_cv= {
    'Ainda não devolvi meu produto e quero saber sobre processo de troca / devolução': 0,
    'Estou arrependido, quero cancelar/trocar o produto': 1,
    'Como utilizar o cupom/vale': 2,
    'Qual o prazo para devolução do valor que paguei?': 3,
    'Como recupero meu login e senha de acesso': 4,
    'Outro': 5
}

filter_problems = [
    'Andamento da minha troca',
    'Cadastro',
    'Promoções',
    'Trocar, cancelar ou devolver',
    'Vales e Reembolso'
]

remove_grams = [
    'nao recebi codigo',
    'nao recebi email',
    'codigo autorizacao postagem',
    'codigo postagem'
]

map_id_template = {
    'Ainda não devolvi meu produto e quero saber sobre processo de troca / devolução': 22,
    'Estou arrependido, quero cancelar/trocar o produto': 32,
    'Como utilizar o cupom/vale': 748,
    'Qual o prazo para devolução do valor que paguei?': 9999,
    'Como recupero meu login e senha de acesso': 9999,
    'Outro': 0
}


# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        raw_data = [ pd.read_parquet(file) for file in input_files ]
        df = pd.concat(raw_data).sample(frac=0.01)

        # data cleaning
        df = df.dropna(subset=['message']).reset_index(drop=True)
        df['message_size'] = df.message.apply(len)
        df = df[df.message_size < 3 * df.message_size.std()].reset_index(drop=True)
        df.problem.replace('Vales e reembolsos', 'Vales e Reembolso', inplace=True)

        # filter problems that are related to our desired voices
        df = df[df.problem.isin(filter_problems)].reset_index(drop=True)

        # defining classes/voices
        df['cv'] = df.apply(lambda x: x.sac_customer_voice if x.sac_customer_voice in (cv_list) else 'Outro', axis=1)

        # label encoder
        df['cv_encoded'] = df['cv'].map(map_cv)

        # train test split
        X = df[['message']]
        y = df['cv_encoded']
        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42 , stratify=y)

        tfidf=TfidfVectorizer(
            max_features=1000,
            max_df=0.95,
            min_df=10,
            ngram_range=(1, 4)
        )

        message_pipeline = Pipeline(
            steps=[
                ('nltk', NLTKPreprocessor()),
                ('tfidf', tfidf)
            ]
        )

        preprocessor = ColumnTransformer(
            transformers=[
                ('msg_pipeline', message_pipeline, 'message'),
            ], 
            remainder='passthrough'
        )

        clf = RandomForestClassifier()

        model = Pipeline(
            steps=[
                ('preprocessor', preprocessor),
                ('classifier', clf)
            ]
        )

        # fit final model
        model.fit(X_train, y_train)
        
        joblib.dump(model, os.path.join(model_path, 'model.joblib'))
        
        print('Training complete.')

    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
